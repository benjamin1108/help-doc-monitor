import asyncio
import argparse
import re
import sys
from pathlib import Path
from datetime import datetime
from playwright.async_api import async_playwright
from rich.console import Console
from rich.progress import Progress
from rich.table import Table
from rich.panel import Panel

# æ·»åŠ  src ç›®å½•åˆ° Python è·¯å¾„
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

from config_loader import config_loader
from src.help_crawler.content_extractor import (
    crawl_and_extract,
    save_content,
    parse_link_file
)

# å¯¼å…¥äº¤äº’å¼åº“
try:
    import questionary
    IS_INTERACTIVE_ENHANCED = True
except ImportError:
    IS_INTERACTIVE_ENHANCED = False

# --- é…ç½® ---
OUTPUT_FORMATS = ['md']
# -----------

CONSOLE = Console()

def list_vendors():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å‚å•†"""
    vendors = config_loader.get_available_vendors()
    
    if IS_INTERACTIVE_ENHANCED:
        table = Table(title="æ‰€æœ‰æ”¯æŒçš„å‚å•†", title_style="bold magenta", show_header=True, header_style="bold blue")
        table.add_column("å‚å•†ä»£ç ", style="cyan")
        table.add_column("å‚å•†åç§°", style="green")
        for vendor, description in vendors.items():
            table.add_row(vendor, description)
        CONSOLE.print(table)
    else:
        print("\nå¯ç”¨çš„å‚å•†:")
        for vendor, description in vendors.items():
            print(f"  {vendor}: {description}")
            
    return vendors


def list_products(vendor: str):
    """åˆ—å‡ºæŒ‡å®šå‚å•†çš„æ‰€æœ‰äº§å“"""
    products = config_loader.get_vendor_products(vendor)
    if not products:
        CONSOLE.print(f"[yellow]å‚å•† {vendor} æ²¡æœ‰é…ç½®äº§å“[/yellow]")
        return None

    if IS_INTERACTIVE_ENHANCED:
        table = Table(title=f"{vendor} å¹³å°å¯ç”¨äº§å“", title_style="bold magenta", show_header=True, header_style="bold blue")
        table.add_column("äº§å“ä»£ç ", style="cyan", max_width=20)
        table.add_column("äº§å“åç§°", style="green")
        table.add_column("æè¿°", style="dim")
        for product_id, product_info in products.items():
            name = product_info.get('name', product_id)
            description = product_info.get('description', '')
            table.add_row(product_id, name, description)
        CONSOLE.print(table)
    else:
        print(f"\n{vendor} å¯ç”¨çš„äº§å“:")
        for product_id, product_info in products.items():
            name = product_info.get('name', product_id)
            description = product_info.get('description', '')
            print(f"  {product_id}: {name}")
            if description:
                print(f"    {description}")
                
    return products


def find_link_files(vendor: str, product: str = None):
    """æŸ¥æ‰¾æŒ‡å®šå‚å•†å’Œäº§å“çš„é“¾æ¥æ–‡ä»¶"""
    links_base_dir = Path("out/links")
    if not links_base_dir.exists():
        return []
    
    vendor_dir = links_base_dir / vendor
    if not vendor_dir.exists():
        return []
    
    if product:
        # æŸ¥æ‰¾ç‰¹å®šäº§å“çš„é“¾æ¥æ–‡ä»¶ï¼Œå°è¯•å¤šç§å‘½åæ¨¡å¼
        patterns = [
            f"{vendor}_{product}_links_*.txt",  # å®Œæ•´å‚å•†å
            f"{vendor[:6]}_{product}_links_*.txt",  # å‚å•†åå‰6ä¸ªå­—ç¬¦ï¼ˆå¦‚ huaweiï¼‰
            f"*_{product}_links_*.txt",  # ä»»æ„å‰ç¼€
        ]
        
        link_files = []
        for pattern in patterns:
            files = list(vendor_dir.glob(pattern))
            link_files.extend(files)
            if files:  # å¦‚æœæ‰¾åˆ°æ–‡ä»¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„æ¨¡å¼
                break
    else:
        # æŸ¥æ‰¾è¯¥å‚å•†æ‰€æœ‰äº§å“çš„é“¾æ¥æ–‡ä»¶
        link_files = list(vendor_dir.glob("*_links_*.txt"))
    
    return link_files


async def interactive_mode_enhanced():
    """å¢å¼ºç‰ˆäº¤äº’å¼æ¨¡å¼"""
    CONSOLE.print(Panel("[bold yellow]ğŸš€ å†…å®¹æå–çˆ¬è™« - äº¤äº’å¼æ¨¡å¼[/bold yellow]", 
                        title="[bold green]Content Crawler[/bold green]", 
                        expand=False, 
                        border_style="blue"))

    while True:
        try:
            action = await questionary.select(
                "è¯·é€‰æ‹©æ‚¨è¦æ‰§è¡Œçš„æ“ä½œ:",
                choices=[
                    questionary.Choice("1. æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„å‚å•†", value='list_vendors'),
                    questionary.Choice("2. å¤„ç†æŒ‡å®šå‚å•†çš„æ‰€æœ‰äº§å“", value='crawl_vendor'),
                    questionary.Choice("3. å¤„ç†æŒ‡å®šå‚å•†çš„æŒ‡å®šäº§å“", value='crawl_product'),
                    questionary.Choice("4. å¤„ç†æ‰€æœ‰å‚å•†çš„æ‰€æœ‰äº§å“", value='crawl_all'),
                    questionary.Separator(),
                    questionary.Choice("5. é€€å‡ºç¨‹åº", value='exit')
                ],
                use_indicator=True
            ).ask_async()

            if action is None or action == 'exit':
                CONSOLE.print("\n[bold yellow]ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å†…å®¹æå–çˆ¬è™«ï¼[/bold yellow]\n")
                break

            if action == 'list_vendors':
                list_vendors()

            elif action == 'crawl_all':
                CONSOLE.print(f"\nğŸš€ å³å°†å¤„ç†æ‰€æœ‰å‚å•†çš„æ‰€æœ‰äº§å“...")
                await process_all_vendors()

            elif action in ['crawl_vendor', 'crawl_product']:
                vendors = config_loader.get_available_vendors()
                vendor = await questionary.select(
                    "è¯·é€‰æ‹©ä¸€ä¸ªå‚å•†:",
                    choices=[questionary.Choice(f"{v} ({d})", value=v) for v, d in vendors.items()]
                ).ask_async()

                if vendor is None: 
                    continue

                if action == 'crawl_product':
                    products = config_loader.get_vendor_products(vendor)
                    if not products:
                        CONSOLE.print(f"[yellow]å‚å•† {vendor} æ²¡æœ‰é…ç½®äº§å“[/yellow]")
                        continue
                    
                    product = await questionary.select(
                        "è¯·é€‰æ‹©è¦å¤„ç†çš„äº§å“:",
                        choices=[questionary.Choice(f"{p_info.get('name', p_id)} ({p_id})", value=p_id) for p_id, p_info in products.items()]
                    ).ask_async()

                    if product is None: 
                        continue
                    
                    product_name = products[product]['name']
                    CONSOLE.print(f"\nğŸš€ å³å°†å¤„ç† [bold blue]{vendors[vendor]}[/bold blue] - [bold green]{product_name}[/bold green]")
                    await process_vendor_product(vendor, product)

                else: # crawl_vendor
                    CONSOLE.print(f"\nğŸš€ å³å°†å¤„ç† [bold blue]{vendors[vendor]}[/bold blue] çš„æ‰€æœ‰äº§å“")
                    await process_vendor_product(vendor)
        
        except KeyboardInterrupt:
            CONSOLE.print("\n\n[bold yellow]ğŸ‘‹ ç¨‹åºå·²å–æ¶ˆï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼[/bold yellow]\n")
            break
        except Exception as e:
            CONSOLE.print(f"[bold red]âŒ å‘ç”Ÿæ„å¤–é”™è¯¯: {e}[/bold red]")


async def interactive_mode():
    """åŸå§‹äº¤äº’å¼æ¨¡å¼ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰"""
    print("\n" + "="*60)
    print("ğŸš€ å†…å®¹æå–çˆ¬è™« - äº¤äº’å¼æ¨¡å¼")
    print("="*60)
    
    while True:
        print("\nğŸ“‹ è¯·é€‰æ‹©æ“ä½œ:")
        print("  1. æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„å‚å•†")
        print("  2. å¤„ç†æŒ‡å®šå‚å•†çš„æ‰€æœ‰äº§å“")
        print("  3. å¤„ç†æŒ‡å®šå‚å•†çš„æŒ‡å®šäº§å“")
        print("  4. å¤„ç†æ‰€æœ‰å‚å•†çš„æ‰€æœ‰äº§å“")
        print("  5. é€€å‡ºç¨‹åº")
        
        try:
            choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-5): ").strip()
            
            if choice == '1':
                list_vendors()
                
            elif choice == '2':
                # å¤„ç†æŒ‡å®šå‚å•†çš„æ‰€æœ‰äº§å“
                list_vendors()
                vendor = input("\nè¯·è¾“å…¥å‚å•†ä»£ç : ").strip().lower()
                
                vendors = config_loader.get_available_vendors()
                if vendor not in vendors:
                    print(f"âŒ æ— æ•ˆçš„å‚å•†ä»£ç : {vendor}")
                    continue
                
                print(f"\nğŸš€ å¼€å§‹å¤„ç† {vendors[vendor]} çš„æ‰€æœ‰äº§å“...")
                await process_vendor_product(vendor)
                
            elif choice == '3':
                # å¤„ç†æŒ‡å®šå‚å•†çš„æŒ‡å®šäº§å“
                list_vendors()
                vendor = input("\nè¯·è¾“å…¥å‚å•†ä»£ç : ").strip().lower()
                
                vendors = config_loader.get_available_vendors()
                if vendor not in vendors:
                    print(f"âŒ æ— æ•ˆçš„å‚å•†ä»£ç : {vendor}")
                    continue
                
                list_products(vendor)
                product = input("\nè¯·è¾“å…¥äº§å“ä»£ç : ").strip().lower()
                
                products = config_loader.get_vendor_products(vendor)
                if product not in products:
                    print(f"âŒ æ— æ•ˆçš„äº§å“ä»£ç : {product}")
                    continue
                
                product_name = products[product]['name']
                print(f"\nğŸš€ å¼€å§‹å¤„ç† {vendors[vendor]} - {product_name}")
                await process_vendor_product(vendor, product)
                
            elif choice == '4':
                print("\nğŸš€ å¼€å§‹å¤„ç†æ‰€æœ‰å‚å•†çš„æ‰€æœ‰äº§å“...")
                await process_all_vendors()

            elif choice == '5':
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å†…å®¹æå–çˆ¬è™«ï¼")
                break
                
            else:
                print("âŒ æ— æ•ˆçš„é€‰é¡¹ï¼Œè¯·è¾“å…¥ 1-5")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹åºå·²å–æ¶ˆï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")


async def process_vendor_product(vendor: str, product: str = None):
    """å¤„ç†æŒ‡å®šå‚å•†å’Œäº§å“çš„å†…å®¹æå–"""
    content_base_dir = Path("out/content")
    
    # æŸ¥æ‰¾å¯¹åº”çš„é“¾æ¥æ–‡ä»¶
    link_files = find_link_files(vendor, product)
    
    if not link_files:
        if product:
            CONSOLE.print(f"[yellow]æœªæ‰¾åˆ° {vendor}/{product} çš„é“¾æ¥æ–‡ä»¶[/yellow]")
        else:
            CONSOLE.print(f"[yellow]æœªæ‰¾åˆ° {vendor} çš„ä»»ä½•é“¾æ¥æ–‡ä»¶[/yellow]")
        return
    
    CONSOLE.print(f"[bold green]æ‰¾åˆ° {len(link_files)} ä¸ªé“¾æ¥æ–‡ä»¶å¾…å¤„ç†ã€‚[/bold green]")
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        
        for link_file in link_files:
            CONSOLE.log(f"\n[cyan]å¤„ç†æ–‡ä»¶: {link_file}[/cyan]")
            
            vendor_name = link_file.parent.name
            product_match = re.search(r"(\w+)_links_", link_file.name.replace(f"{vendor_name}_", ""))
            product_key = product_match.group(1) if product_match else "unknown"

            documents_to_crawl = parse_link_file(link_file)
            if not documents_to_crawl:
                CONSOLE.log(f"[yellow]åœ¨ {link_file} ä¸­æœªæ‰¾åˆ°æ–‡æ¡£ã€‚è·³è¿‡ã€‚[/yellow]")
                continue

            with Progress(*Progress.get_default_columns(), console=CONSOLE) as progress:
                task = progress.add_task(f"[green]çˆ¬å– {vendor_name}/{product_key}", total=len(documents_to_crawl))

                for doc in documents_to_crawl:
                    extracted_data = await crawl_and_extract(page, doc['url'], vendor_name)
                    if extracted_data:
                        full_metadata = {
                            "url": doc['url'],
                            "vendor": vendor_name,
                            "product": product_key,
                            "crawl_time": datetime.now().isoformat(),
                            "title": doc['title'], # Use title from link file as primary
                            **extracted_data
                        }
                        # å¦‚æœæå–å™¨æ²¡èƒ½è·å–æ ‡é¢˜ï¼Œä½¿ç”¨é“¾æ¥æ–‡ä»¶ä¸­çš„æ ‡é¢˜
                        if not full_metadata["title"] or full_metadata["title"] == "Untitled":
                            full_metadata["title"] = doc['title']

                        save_content(content_base_dir, full_metadata, OUTPUT_FORMATS)
                    
                    progress.update(task, advance=1)

            CONSOLE.log(f"[bold green]âœ” å®Œæˆ {vendor_name}/{product_key} çš„å†…å®¹æå–ã€‚[/bold green]")
        
        await browser.close()


async def process_all_vendors():
    """å¤„ç†æ‰€æœ‰å‚å•†çš„æ‰€æœ‰äº§å“"""
    vendors = config_loader.get_available_vendors()
    for vendor in vendors:
        await process_vendor_product(vendor)


async def main():
    parser = argparse.ArgumentParser(
        description="ä»é“¾æ¥æ–‡ä»¶ä¸­çˆ¬å–å†…å®¹æˆ–å¤„ç†å•ä¸ªURL",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s                                          # å¯åŠ¨äº¤äº’å¼æ¨¡å¼
  %(prog)s --url https://example.com --vendor aliyun # çˆ¬å–å•ä¸ªURL
  %(prog)s --vendor aliyun                          # å¤„ç†é˜¿é‡Œäº‘æ‰€æœ‰äº§å“çš„é“¾æ¥æ–‡ä»¶
  %(prog)s --vendor aliyun --product vpc            # å¤„ç†é˜¿é‡Œäº‘VPCäº§å“çš„é“¾æ¥æ–‡ä»¶
  %(prog)s --list-vendors                           # åˆ—å‡ºæ‰€æœ‰å‚å•†
  %(prog)s --vendor aliyun --list-products          # åˆ—å‡ºé˜¿é‡Œäº‘æ‰€æœ‰äº§å“
        """
    )
    
    parser.add_argument("--url", type=str, help="A single URL to crawl and extract content from.")
    parser.add_argument("--vendor", type=str, help="Specify a vendor for single URL crawling or batch processing.")
    parser.add_argument("--product", type=str, help="Specify a product for batch processing (requires --vendor).")
    parser.add_argument("--list-vendors", action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å‚å•†')
    parser.add_argument("--list-products", action='store_true', help='åˆ—å‡ºæŒ‡å®šå‚å•†çš„æ‰€æœ‰äº§å“ï¼ˆéœ€è¦é…åˆ--vendorä½¿ç”¨ï¼‰')
    
    args = parser.parse_args()

    # å¦‚æœæ²¡æœ‰æä¾›ä»»ä½•å‚æ•°ï¼Œå¯åŠ¨äº¤äº’å¼æ¨¡å¼
    if len(sys.argv) == 1:
        if IS_INTERACTIVE_ENHANCED:
            await interactive_mode_enhanced()
        else:
            CONSOLE.print("[yellow]æç¤ºï¼šä¸ºäº†è·å¾—æ›´å¥½çš„äº¤äº’ä½“éªŒï¼Œå»ºè®®å®‰è£… `questionary` åº“ã€‚[/yellow]")
            CONSOLE.print("[yellow]è¿è¡Œ `pip install questionary` è¿›è¡Œå®‰è£…ã€‚[/yellow]")
            await interactive_mode()
        return

    # åˆ—å‡ºå‚å•†
    if args.list_vendors:
        list_vendors()
        return

    # åˆ—å‡ºäº§å“
    if args.list_products:
        if not args.vendor:
            CONSOLE.print("[red]ä½¿ç”¨ --list-products æ—¶å¿…é¡»æŒ‡å®š --vendor[/red]")
            return
        list_products(args.vendor)
        return

    content_base_dir = Path("out/content")

    # å•ä¸ªURLå¤„ç†é€»è¾‘
    if args.url:
        # å½“ä½¿ç”¨ --url æ—¶ï¼Œ--vendor å¿…é¡»æä¾›
        if not args.vendor:
            CONSOLE.log("[bold red]é”™è¯¯ï¼šä½¿ç”¨ --url æ—¶ï¼Œå¿…é¡»é€šè¿‡ --vendor æŒ‡å®šå‚å•†ã€‚[/bold red]")
            parser.print_help()
            return

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()

            CONSOLE.log(f"[bold cyan]Processing single URL: {args.url}[/bold cyan]")
            extracted_data = await crawl_and_extract(page, args.url, args.vendor)
            if extracted_data:
                full_metadata = {
                    "url": args.url,
                    "vendor": args.vendor,
                    "product": "single_url",
                    "crawl_time": datetime.now().isoformat(),
                    **extracted_data
                }
                save_content(content_base_dir, full_metadata, OUTPUT_FORMATS)
                CONSOLE.log(f"[bold green]âœ” Saved output to out/content/{args.vendor}/single_url/[/bold green]")
            
            await browser.close()
        return

    # æ‰¹é‡å¤„ç†é€»è¾‘
    if args.vendor:
        # å¤„ç†æŒ‡å®šå‚å•†ï¼ˆå’Œå¯é€‰çš„äº§å“ï¼‰
        await process_vendor_product(args.vendor, args.product)
        return

    # å¦‚æœæ²¡æœ‰æŒ‡å®šå‚å•†ï¼Œåˆ™å¤„ç†æ‰€æœ‰é“¾æ¥æ–‡ä»¶ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    links_base_dir = Path("out/links")
    if not links_base_dir.exists():
        CONSOLE.log("[bold red]é”™è¯¯: 'out/links' ç›®å½•æœªæ‰¾åˆ°ã€‚[/bold red]")
        return

    link_files = list(links_base_dir.glob("*/*_links_*.txt"))
    if not link_files:
        CONSOLE.log("[bold yellow]åœ¨ 'out/links' ç›®å½•ä¸­æœªæ‰¾åˆ°é“¾æ¥æ–‡ä»¶ã€‚[/bold yellow]")
        return

    CONSOLE.log(f"[bold green]æ‰¾åˆ° {len(link_files)} ä¸ªé“¾æ¥æ–‡ä»¶å¾…å¤„ç†ã€‚[/bold green]")

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()

        for link_file in link_files:
            CONSOLE.log(f"\n[cyan]å¤„ç†æ–‡ä»¶: {link_file}[/cyan]")
            
            vendor = link_file.parent.name
            product_match = re.search(r"(\w+)_links_", link_file.name.replace(f"{vendor}_", ""))
            product_key = product_match.group(1) if product_match else "unknown"

            documents_to_crawl = parse_link_file(link_file)
            if not documents_to_crawl:
                CONSOLE.log(f"[yellow]åœ¨ {link_file} ä¸­æœªæ‰¾åˆ°æ–‡æ¡£ã€‚è·³è¿‡ã€‚[/yellow]")
                continue

            with Progress(*Progress.get_default_columns(), console=CONSOLE) as progress:
                task = progress.add_task(f"[green]çˆ¬å– {vendor}/{product_key}", total=len(documents_to_crawl))

                for doc in documents_to_crawl:
                    extracted_data = await crawl_and_extract(page, doc['url'], vendor)
                    if extracted_data:
                        full_metadata = {
                            "url": doc['url'],
                            "vendor": vendor,
                            "product": product_key,
                            "crawl_time": datetime.now().isoformat(),
                            "title": doc['title'], # Use title from link file as primary
                            **extracted_data
                        }
                        # å¦‚æœæå–å™¨æ²¡èƒ½è·å–æ ‡é¢˜ï¼Œä½¿ç”¨é“¾æ¥æ–‡ä»¶ä¸­çš„æ ‡é¢˜
                        if not full_metadata["title"] or full_metadata["title"] == "Untitled":
                            full_metadata["title"] = doc['title']

                        save_content(content_base_dir, full_metadata, OUTPUT_FORMATS)
                    
                    progress.update(task, advance=1)

            CONSOLE.log(f"[bold green]âœ” å®Œæˆ {vendor}/{product_key} çš„å†…å®¹æå–ã€‚[/bold green]")

        await browser.close()

if __name__ == "__main__":
    asyncio.run(main()) 